\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Timeline of the history of the Universe. The Epoch of Reionization marks the era when the first stars and galaxies formed and ionized the neutral hydrogen in the Universe. Image credit: NAOJ.\relax }}{2}{figure.caption.5}
\contentsline {figure}{\numberline {1.2}{\ignorespaces A cartoon diagram of the observable Universe, centered on us. Close-by, galaxy observations have mapped out cosmic web structure in our nearby Universe (image credit: SDSS). Far-away, the cosmic microwave background is observed at a redshift of $z \sim 1100$ (image credit: WMAP). The Epoch of Reionization represents a largely unexplored era between the two, and can be probed by measuring red-shifted $21$\tmspace +\thinmuskip {.1667em}cm radiation from neutral hydrogen.\relax }}{5}{figure.caption.6}
\contentsline {figure}{\numberline {1.3}{\ignorespaces The evolution of the global $21$\tmspace +\thinmuskip {.1667em}cm signal, starting with the Dark Ages, through galaxy formation and reionization (image credit: \citet {pritchard_loeb2012}). The work in this thesis mainly focuses on a redshift range of $6 < z < 12$ when reionization is expected to progress and complete.\relax }}{6}{figure.caption.7}
\contentsline {figure}{\numberline {1.4}{\ignorespaces The theoretical evolution of the cross-$21$\tmspace +\thinmuskip {.1667em}cm power spectrum for a specific model (image credit: \citet {barkana2009}), where the neutral fraction $x_{HI} = 10\%$, $30\%$, $50\%$, $70\%$, $90\%$, and $98\%$ from top to bottom at large $k$. This figure shows the expected evolution of the power spectrum which interferometers seek to measure.\relax }}{11}{figure.caption.8}
\contentsline {figure}{\numberline {1.5}{\ignorespaces A cartoon diagram of the ``EoR Window" and ``wedge" of foreground contamination in Fourier space (image credit: \citet {dillon_et_al2015b}). A foreground avoidance approach makes power spectrum measurements in the window, while a foreground subtraction approach subtracts out foregrounds so that measurements can be made in the wedge. The overall power spectrum measurement space is limited by an interferometer's field of view and angular resolution along the horizontal axis, and spectral resolution and intrinsic foregrounds along the vertical axis.\relax }}{13}{figure.caption.9}
\contentsline {figure}{\numberline {1.6}{\ignorespaces A PAPER antenna in the Karoo Desert in South Africa. A dual-polarization dipole sits at the center, surrounded by wire mesh panels that measure 2\tmspace +\thinmuskip {.1667em}m on each side.\relax }}{16}{figure.caption.10}
\contentsline {figure}{\numberline {1.7}{\ignorespaces A HERA dish in the Karoo Desert in South Africa. Wire-mesh, PVC pipes, and wooden structures serve as the foundation for the 14\tmspace +\thinmuskip {.1667em}m diameter parabola. A PAPER dipole is suspended upside-down with a wire pulley-system and surrounded by a prototype wire-mesh skirt structure. HERA-350 will use an updated design for its feed; however, HERA's initial data releases use the old PAPER infrastructure as depicted here.\relax }}{18}{figure.caption.11}
\contentsline {figure}{\numberline {1.8}{\ignorespaces The full HERA-350 array (image credit: \citet {deboer_et_al2017}). The array is comprised of a segmented densely-packed core (to optimize redundancy for a foreground avoidance approach) and surrounding outrigger elements (for imaging capabilities).\relax }}{18}{figure.caption.12}
\contentsline {figure}{\numberline {1.9}{\ignorespaces Published upper limits on the EoR placed by different $21$\tmspace +\thinmuskip {.1667em}cm experiments, prior to the work in this thesis. All PAPER results shown (PAPER-32 is in cyan and magenta, and PAPER-64 is in gray) are suspect to the errors discussed throughout this work and are superseded by the ones presented in Chapter \ref {c.PSA64}.\relax }}{20}{figure.caption.13}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Our toy model dataset to which we apply different weighting schemes to in order to investigate signal loss. We model a mock foreground-only visibility with a sinusoid signal that varies smoothly in time and frequency. We model a mock visibility of an EoR signal as a random Gaussian signal. We add the two together to form $\textbf {x} = \textbf {x}_{\rm FG} + \textbf {x}_{\rm EoR}$. Real parts are shown here.\relax }}{29}{figure.caption.14}
\contentsline {figure}{\numberline {2.2}{\ignorespaces The estimated covariance matrices (top row) and inverse covariance-weighted data (bottom row) for FG only (left), EoR only (middle), and FG + EoR (right). Real parts are shown here.\relax }}{30}{figure.caption.15}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Resulting power spectrum estimates for the toy model simulation described in Chapter \ref {sec:toymodel} --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). The power spectrum of the foregrounds peaks at a $k$-mode based on the frequency of the sinusoid used to create the mock FG signal. In the two panels, we compare using empirically estimated inverse covariance weighting where $\textbf {C}$ is derived from the data (left), and projecting out the zeroth eigenmode only (right). In the former case, signal loss arises from the coupling of the eigenmodes of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ to the data. There is negligible signal loss when all eigenmodes besides the foreground one are no longer correlated with the data. \relax }}{31}{figure.caption.16}
\contentsline {figure}{\numberline {2.4}{\ignorespaces The convergence level, as defined by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:converge}\unskip \@@italiccorr )}}, of empirically estimated covariances of mock EoR signals with different numbers of independent samples. In red, the mock EoR signal is comprised entirely of independent samples (100 of them). Subsequent colors show time-averaged signals. As the number of realizations increases, we see that the empirical covariances approach the true covariances. With more independent samples, the quicker an empirical covariance converges (i.e., the quicker it decouples from the data), and the less signal loss we would expect to result.\relax }}{34}{figure.caption.17}
\contentsline {figure}{\numberline {2.5}{\ignorespaces The convergence level, as defined by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:converge_eig}\unskip \@@italiccorr )}}, of empirically estimated eigenvectors for different numbers of mock data realizations. The colors span from the 0th eigenmode (has the highest eigenvalue) to the 19th eigenmode (has the lowest eigenvalue), where they are ordered by eigenvalue in descending order. This figure shows that the zeroth eigenmode converges the quickest, implying that eigenvectors with eigenvalues that are substantially different than the rest (the FG-dominated mode has a much higher eigenvalue than the EoR modes) are able to converge to the true eigenvectors the quickest. On the other hand, eigenmodes $1$-$19$ have similar eigenvalues and are slower to converge because of degeneracies between them.\relax }}{35}{figure.caption.18}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Our ``fringe-rate filtered" (time-averaged) toy model dataset. We average every four samples together, yielding $25$ independent samples in time. Real parts are shown here.\relax }}{35}{figure.caption.19}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Resulting power spectrum estimate for the ``fringe-rate filtered" (time-averaged) toy model simulation --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). We use empirically estimated inverse covariance weighting where $\textbf {C}$ is computed from the data. There is a larger amount of signal loss than for the non-averaged data, a consequence of weighting by eigenmodes that are more strongly coupled to the data due to there being fewer independent modes in the data.\relax }}{37}{figure.caption.20}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Resulting power spectra estimates for our ``fringe-rate filtered" (time-averaged) toy model simulation --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). We show four alternate weighting options that each minimize signal loss, including modeling the covariance matrix of EoR (upper left), regularizing $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ by adding an identity matrix to it (upper right), using only the first three eigenmodes of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ (lower left), and keeping only the diagonal elements of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ (lower right). The first case (upper left) is not feasible in practice since we do not know $\textbf {C}_{\rm FG}$ and $\textbf {C}_{\rm EoR}$ like we do in the toy model.\relax }}{38}{figure.caption.21}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Error estimation from bootstrapping as a function of the number of elements drawn per bootstrap when sampling with replacement. The star represents the standard deviation of $N_{\rm boot}=500$ bootstraps, each created by drawing $1000$ elements (with replacement) from a length $1000$ array of a Gaussian random signal. The black points correspond to time-averaged data (correlated data) which has $100$ independent samples. They illustrate how errors can be under-estimated if drawing more elements than there are independent samples in the data. The estimated errors match up with the theoretical prediction only at $N=100$.\relax }}{45}{figure.caption.22}
\contentsline {figure}{\numberline {2.10}{\ignorespaces A null jackknife test shown as the power spectrum difference between two measurements (black), compared to the power spectrum of noise alone (green). Because the null test is not consistent with noise, it suggests the presence of a systematic in either $\textbf {x}_{1}$ or $\textbf {x}_{2}$. Null tests of clean measurements should be consistent with thermal noise.\relax }}{50}{figure.caption.23}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Power spectrum estimates for $\textbf {x}_{1}$ and $\textbf {x}_{2}$, two jackknives of the toy model. They suggest the presence of a systematic in $\textbf {x}_{2}$ only, illustrating how jackknives can be used to tease out excesses. Clean measurements should remain consistent despite the jackknife taken.\relax }}{50}{figure.caption.24}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces The PAPER-64 antenna layout. We use only $10$ of the $30$ m East/West baselines for the analysis in this chapter (i.e., a subset of the shortest horizontal spacings).\relax }}{53}{figure.caption.25}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Top: the normalized optimal power-spectrum sensitivity weighting in fringe-rate space for our fiducial baseline and Stokes I polarization beam. Bottom: the time domain convolution kernel corresponding to the top panel. Real and imaginary components are illustrated in cyan and magenta, respectively, with the absolute amplitude in black. The fringe-rate filter acts as an integration in time, increasing sensitivity but reducing the number of independent samples in the dataset.\relax }}{56}{figure.caption.26}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Illustration of the power spectrum amplitude of five different power spectrum terms, each a function of visibility data ($\textbf {x}$), simulated injected EoR signal ($\textbf {e}$), or both ($\textbf {r}$). This figure shows how these quantities behave as the power level of the injected EoR signal increases (along the x-axis). The details of the simulation used to generate the figure is explained in Chapter \ref {sec:Practice}; here we sample a larger $P_{\rm in}$ range and fit smooth polynomials to our data points to make an illustrative example. We emphasize that the output power spectrum in black ($\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle P$}\mathaccent "0362{P}_{\rm out}=\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_r$) approximates the (lossy) power spectrum estimate that is output by our analysis pipeline prior to any signal loss adjustments. Roughly speaking, it can be compared to the input signal level ($P_{\rm in}$) to estimate the amount of signal loss. Left: Empirical inverse covariance weighting is used in power spectrum estimation, as done in \citet {ali_et_al2015}. The dotted diagonal black line indicates perfect 1:1 input-to-output mapping (no signal loss). The gray horizontal line is the power spectrum value of data alone, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_{x}$ (it does not depend on injected power). The green signal-signal component is the term used in \citet {ali_et_al2015} to estimate signal loss. It is significantly higher than $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_{r}$ (black) when the cross-terms (red) are large and negative (black $=$ green $+$ red $+$ blue). In the regime where cross-correlations between signal and data are not dominant (small and large $P_{\rm in}$), the cross-terms have a noise-like term with width $\sqrt {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_e}\sqrt {\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_x}$. However, at power levels comparable to the data (the middle region), the cross-terms can produce large, negative estimates due to couplings between $\textbf {x}$ and $\textbf {e}$ which affect $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}_{r}$. This causes the difference between the green curve (which exhibits negligible loss at the data-only power spectrum value) and the black curve (which exhibits $\sim 4$ orders of magnitude of loss). Right: The same power spectrum terms illustrated for the uniform weighted case.\relax }}{60}{figure.caption.27}
\contentsline {figure}{\numberline {3.4}{\ignorespaces An illustrative example (for the PAPER-64 analysis using uniform weighting and $k=0.393$\tmspace +\thinmuskip {.1667em}$h$ Mpc$^{-1}$) of how the mean of $P_{\rm out}$ (left) and standard deviation of $P_{\rm out}$ (right) behave as a function of $P_{\rm in}$. Polynomials are fit to each (red) to describe how $\mathaccentV {bar}016y$ and $\sigma $ evolve with $x$ (injection level), respectively, for the computation of the Jeffreys prior as defined in Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:jeffreys_final}\unskip \@@italiccorr )}}. The polynomial fits for this example are $y = (-5.1 \times 10^{-15})x^{2} + x + (1.5 \times 10^{7})$ and $y = (5.0 \times 10^{-13})x^{2} + 0.2 x + 10^{7}$ for $\mathaccentV {bar}016y$ and $\sigma $, respectively.\relax }}{63}{figure.caption.28}
\contentsline {figure}{\numberline {3.5}{\ignorespaces An example of the typical Jeffreys prior shape for the PAPER-64 analysis as computed by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:jeffreys_final}\unskip \@@italiccorr )}} (black). We smooth the prior using a sliding boxcar average over every $5$ injection levels (red). Most noticeably, the Jeffreys prior is not constant with $P_{\rm in}$, meaning a uniform prior would be an informative prior.\relax }}{63}{figure.caption.29}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Signal loss transfer functions showing the relationship of $P_{\rm in}$ and $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle P$}\mathaccent "0362{P}_{\rm out}$, as defined by Equations \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:Pin}\unskip \@@italiccorr )}} and \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:sigloss}\unskip \@@italiccorr )}}. Power spectra values (black points) are generated for $20$ realizations of $\textbf {e}$ per signal injection level. Since our $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle P$}\mathaccent "0362{P}_{\rm out}$ values are well-approximated by a Gaussian distribution, we fit Gaussians to each injection level based on the mean and variance of the simulation outputs. This entire likelihood function is then multiplied by a Jeffreys prior for $p(P_{\rm in}$), with the final result shown as the colored heat-maps on top of the points. Two cases are displayed: empirically estimated inverse covariance weighted PAPER-64 data (left) and uniform-weighted data (right). The dotted black diagonal lines mark a perfect unity mapping, and the solid gray horizontal line denotes the power spectrum value of the data $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {P}$}\mathaccent "0362{\textbf {P}}_{x}$, from which a posterior distribution for the signal is extracted. From these plots, it is clear that the weighted case results in $\sim 4$ orders of magnitude of signal loss at the data-only power spectrum value, whereas the uniform-weighted case does not exhibit loss. The general shape of these transfer functions are also shown by the black curves in Figure \ref {fig:sigloss_terms} for comparison.\relax }}{65}{figure.caption.30}
\contentsline {figure}{\numberline {3.7}{\ignorespaces A power spectrum of a subset of PAPER-64 data illustrating the use of empirical inverse covariance weighting. The solid red curve is the $2\sigma $ upper limit on the EoR signal estimated from our signal injection framework using empirical inverse covariance weighting. Shown for comparison is the lossy limit prior to signal loss estimation (dashed red). The theoretical $2\sigma $ thermal noise level prediction based on observational parameters is in green, whose calculation is detailed in Chapter \ref {sec:Error}. Additionally, the power spectrum result for the uniform weighted case is shown in three different ways: power spectrum values (black and gray points as positive and negative values, respectively, with $2\sigma $ error bars from bootstrapping), the $2\sigma $ upper limit on the EoR signal using our full signal injection framework (solid blue), and the measured power spectrum values with $2\sigma $ thermal noise errors (gray shaded regions). The vertical dashed black lines signify the horizon limit for this analysis using $30$\tmspace +\thinmuskip {.1667em}m baselines. In this example, we see that the lossy power spectrum limit is $\sim 4$ orders of magnitude too low when using empirical inverse covariance weighting.\relax }}{66}{figure.caption.31}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Power spectra $2\sigma $ upper limits for $k=0.393$\tmspace +\thinmuskip {.1667em}$h$ Mpc$^{-1}$ for fringe-rate filtered PAPER-64 data. Top: Values are shown before (dashed red) and after (solid red) signal loss estimation via our signal injection framework as a function of number of eigenmodes of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ that are down-weighted. This regularization knob is tuned from $0$ modes on the left (i.e., unweighted) to $21$ modes on the right (i.e., the full inverse covariance estimator). $\sim 4$ orders of magnitude of signal loss results when using empirically estimated inverse covariance weighting. Bottom: Power spectrum upper limits before (dashed red) and after (solid red) signal loss estimation as a function of identity added to the empirical covariance. This regularization knob is tuned from $\gamma = 10^{-4}$ on the right (i.e., very little regularization) to $\gamma = 1$ on the left (see main text for the definition of $\gamma $). Also plotted in both panels for comparison are $2\sigma $ power spectrum upper limits for the uniform-weighted case (blue) and inverse variance weighted case (black); both are after signal loss estimation. Finally, a theoretical prediction for noise ($2\sigma $ error) is plotted as green. In the PAPER-64 analysis in this paper, we choose to use a regularization scheme of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}_{\rm eff} \equiv 0.09 \tmspace +\thinmuskip {.1667em} $Tr($\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}})\textbf {I} + \setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ ($\gamma = 0.09$) as a simple example of regularization that minimizes loss, and note that the power spectrum limits using this type of regularization are roughly constant across a large range of values of $\gamma $.\relax }}{68}{figure.caption.32}
\contentsline {figure}{\numberline {3.9}{\ignorespaces A power spectrum of a subset of PAPER-64 data illustrating the use of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}_{\rm eff}$ to minimize signal loss. The solid red curve is the $2\sigma $ upper limit on the EoR signal estimated from our signal injection framework. The theoretical $2\sigma $ thermal noise level prediction based on observational parameters is in green. Additionally, the power spectrum result for the uniform weighted case is shown in three different ways: power spectrum values (black and gray points as positive and negative values, respectively, with $2\sigma $ error bars from bootstrapping), the $2\sigma $ upper limit on the EoR signal using our full signal injection framework (solid blue), and the measured power spectrum values with $2\sigma $ thermal noise errors (gray shaded regions). The vertical dashed black lines signify the horizon limit for this analysis using $30$\tmspace +\thinmuskip {.1667em}m baselines. This power spectrum result does not use the full dataset's sensitivity as in \citet {ali_et_al2015} and Kolopanis et al. (\textit {in prep.}), though we include all analysis changes which have mostly stemmed from revisions regarding signal loss, bootstrapping, and the theoretical error computation. We see that the regularization scheme used here produces limits similar to the unweighted limits.\relax }}{70}{figure.caption.33}
\contentsline {figure}{\numberline {3.10}{\ignorespaces $2\sigma $ power spectrum errors (from bootstrap variances) for a noise simulation (computed via Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:noise}\unskip \@@italiccorr )}} using PAPER-64 observing parameters) using two different bootstrapping methods. The noise is fringe-rate filtered and a weighting matrix of $\textbf {I}$ (uniform-weighted) is used in order to disentangle the effects of bootstrapping from signal loss. The bootstrapping method used in \citet {ali_et_al2015} is shown in gray, where bootstrapping occurs along both the baseline and time axes. This underestimates errors by sampling more values than independent ones in the dataset (fringe-rate filtering reduces the number of independent samples along time). We use the method illustrated by the black curve in our updated analysis, where bootstrapping only occurs along the baseline axis. We find that these revised limits agree with the $2\sigma $ analytic prediction for noise (green).\relax }}{74}{figure.caption.34}
\contentsline {figure}{\numberline {3.11}{\ignorespaces An updated prediction for the thermal noise level of PAPER-64 data (black) is shown in comparison to previously published sensitivity limits (gray), both computed for the parameters and methods used in \citet {ali_et_al2015}. Major factors that contribute to the discrepancy are $ \Omega _{\rm eff}$, $N_{\rm days}$ and $N_{\rm bls}$, as in Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:sense}\unskip \@@italiccorr )}} and described in Chapter \ref {sec:Error}, which when combined decreases our sensitivity (higher noise floor) by a factor of $\sim 7$ in mK$^{2}$.\relax }}{78}{figure.caption.35}
\contentsline {figure}{\numberline {3.12}{\ignorespaces The power spectrum for a noise simulation that mimics the noise level of a subset of PAPER-64 data, where the solid red curve is the $2\sigma $ upper limit on the EoR signal estimated from our signal injection framework using $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}_{\rm eff}$. The theoretical $2\sigma $ thermal noise level prediction based on observational parameters (calculated by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:sense}\unskip \@@italiccorr )}}) is in green. Additionally, the power spectrum result for the uniform weighted case is shown in three different ways: power spectrum values (black and gray points as positive and negative values, respectively, with $2\sigma $ error bars from bootstrapping), the $2\sigma $ upper limit on the EoR signal using our full signal injection framework (solid blue), and the measured power spectrum values with $2\sigma $ thermal noise errors (gray shaded regions). The vertical dashed black lines signify the horizon limit for this analysis using $30$\tmspace +\thinmuskip {.1667em}m baselines. We highlight that the bootstrapped data points and thermal noise prediction show good agreement, while the limits from the full injection framework (red and blue) are inflated due to the additional inclusion of sample variance that comes from the injection simulations.\relax }}{79}{figure.caption.36}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Differenced power spectrum results (with $2\sigma $ bootstrapped errors) for three null tests, where a jackknife is taken along the baseline axis (top left), LST axis (top right), and even/odd Julian date axis (bottom). The results shown are unweighted (no signal loss), where the power spectrum values plotted are computed from the difference between two power spectra produced on either side of the jackknife axis. The gray shaded region in each plot is the estimated $2\sigma $ theoretical noise limit given the parameters of each test. We find that there are no significant systematics for $k > \pm 0.2$\tmspace +\thinmuskip {.1667em}$h$ Mpc$^{-1}$ for all three tests. However, we find that all tests exhibit an extra variance at $k$-values near the horizon ($k\sim \pm 0.1$\tmspace +\thinmuskip {.1667em}$h$ Mpc$^{-1}$), likely due to foreground-noise coupling terms when foregrounds are brightest. Additionally, we find that the LST null test is not fully consistent with zero, implying a bias that is LST dependent and likely caused by varying foregrounds.\relax }}{82}{figure.caption.37}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The PAPER-128 antenna layout. There are 112 antennas arranged in a grid layout which are used for power spectrum analyses. The addition of 16 outrigger antennas is used to increase \textit {uv}-plane sampling for imaging analyses.\relax }}{88}{figure.caption.38}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Visibility amplitudes as a function of LST for different Julian days of data (colors). The left column shows the data before (top) and after (bottom) the flagging of outlier days for Epoch 1. The right column shows similar data for Epoch 2. After flagging, visibilities show good day-to-day agreement across an epoch.\relax }}{90}{figure.caption.40}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Waterfall plots of visibility amplitudes for a ``good" reference day (left) in Epoch 2 and ``bad" day (right). We exclude corrupted data for specific days found with our metric.\relax }}{91}{figure.caption.41}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Waterfall plots of visibility amplitudes for four different polarizations and two different baselines. Antenna 26 is found to be cross-polarized because its feed was rotated by 90 degrees, and hence its ``X" and ``Y" polarization states are mis-labeled. Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:psa128_crosspol}\unskip \@@italiccorr )}} captures visibility amplitudes like the ones shown here in order to automatically detect cross-polarized antennae.\relax }}{92}{figure.caption.42}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Flagged antennas, found using Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:psa128_badant}\unskip \@@italiccorr )}}, are marked in black for each antenna number (x-axis) and Julian date (y-axis). The left column shows flags for XX polarization, and the right column shows flags for YY polarization. The top row shows flags for Epoch 1 and the bottom row shows flags for Epoch 2. We remove antennas that are flagged greater than 50\% of the time per epoch.\relax }}{93}{figure.caption.43}
\contentsline {figure}{\numberline {5.6}{\ignorespaces {\tt FirstCal} phase solutions for Antenna 1 (Epoch 1, XX polarization) where no antennas are flagged (top left) and some antennas are flagged (via the methods described in Chapter \ref {sec:psa128_badant}, top right). Omnical $\chi ^{2}$ results are also shown for the two cases (bottom). We do not include any of the 16 dead antennas associated with correlator FX2. It is crucial to flag misbehaving antennas (especially extreme outlier antennas) prior to redundant calibration, motivating the development of automated quality assessment tools prior to the post-processing of data.\relax }}{95}{figure.caption.44}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Power spectrum results for PAPER-128 season 1 data for two redshifts (rows) and two epochs (columns), using one baseline separation-type only (30\tmspace +\thinmuskip {.1667em}m East/West baselines). Black and gray points represent positive and negative power spectrum values, respectively, with $2\sigma $ error bars determined from bootstrapping. The $2\sigma $ theoretical noise sensitivity prediction is shown in green. Gray shaded regions correspond to theoretical errors on each data point.\relax }}{98}{figure.caption.45}
\addvspace {10\p@ }
\addvspace {10\p@ }
