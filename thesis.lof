\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Timeline of the history of the Universe. The Epoch of Reionization marks the era when the first stars and galaxies formed and ionized the neutral hydrogen in the Universe. Image credit: NAOJ.\relax }}{2}{figure.caption.5}
\contentsline {figure}{\numberline {1.2}{\ignorespaces A cartoon diagram of the observable Universe, centered on us. Close-by, galaxy observations have mapped out cosmic web structure in our nearby Universe (image credit: SDSS). Far-away, the cosmic microwave background is observed at a redshift of $z \sim 1100$ (image credit: WMAP). The Epoch of Reionization represents a largely unexplored era between the two, and can be probed by measuring red-shifted $21$\tmspace +\thinmuskip {.1667em}cm radiation from neutral hydrogen.\relax }}{5}{figure.caption.6}
\contentsline {figure}{\numberline {1.3}{\ignorespaces The evolution of the global $21$\tmspace +\thinmuskip {.1667em}cm signal, starting with the Dark Ages, through galaxy formation and reionization (image credit: \citet {pritchard_loeb2012}). The work in this thesis mainly focuses on a redshift range of $6 < z < 12$ when reionization is expected to progress and complete.\relax }}{6}{figure.caption.7}
\contentsline {figure}{\numberline {1.4}{\ignorespaces The theoretical evolution of the cross-$21$\tmspace +\thinmuskip {.1667em}cm power spectrum for a specific model (image credit: \citet {barkana2009}), where the neutral fraction $x_{HI} = 10\%$, $30\%$, $50\%$, $70\%$, $90\%$, and $98\%$ from top to bottom at large $k$. This figure shows the expected evolution of the power spectrum which interferometers seek to measure.\relax }}{11}{figure.caption.8}
\contentsline {figure}{\numberline {1.5}{\ignorespaces A cartoon diagram of the ``EoR Window" and ``wedge" of foreground contamination in Fourier space (image credit: \citet {dillon_et_al2015b}). A foreground avoidance approach makes power spectrum measurements in the window, while a foreground subtraction approach subtracts out foregrounds so that measurements can be made in the wedge. The overall power spectrum measurement space is limited by an interferometer's field of view and angular resolution along the horizontal axis, and spectral resolution and intrinsic foregrounds along the vertical axis.\relax }}{13}{figure.caption.9}
\contentsline {figure}{\numberline {1.6}{\ignorespaces A PAPER antenna in the Karoo Desert in South Africa. A dual-polarization dipole sits at the center, surrounded by wire mesh panels that measure 2\tmspace +\thinmuskip {.1667em}m on each side.\relax }}{16}{figure.caption.10}
\contentsline {figure}{\numberline {1.7}{\ignorespaces A HERA dish in the Karoo Desert in South Africa. Wire-mesh, PVC pipes, and wooden structures serve as the foundation for the 14\tmspace +\thinmuskip {.1667em}m diameter parabola. A PAPER dipole is suspended upside-down with a wire pulley-system and surrounded by a prototype wire-mesh skirt structure. HERA-350 will use an updated design for its feed; however, HERA's initial data releases use the old PAPER infrastructure as depicted here.\relax }}{18}{figure.caption.11}
\contentsline {figure}{\numberline {1.8}{\ignorespaces The full HERA-350 array (image credit: \citet {deboer_et_al2017}). The array is comprised of a segmented densely-packed core (to optimize redundancy for a foreground avoidance approach) and surrounding outrigger elements (for imaging capabilities).\relax }}{18}{figure.caption.12}
\contentsline {figure}{\numberline {1.9}{\ignorespaces Published upper limits on the EoR placed by different $21$\tmspace +\thinmuskip {.1667em}cm experiments, prior to the work in this thesis. All PAPER results shown (PAPER-32 is in cyan and magenta, and PAPER-64 is in gray) are suspect to the errors discussed throughout this work and are superseded by the ones presented in Chapter \ref {c.PSA64}.\relax }}{20}{figure.caption.13}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Our toy model dataset to which we apply different weighting schemes to in order to investigate signal loss. We model a mock foreground-only visibility with a sinusoid signal that varies smoothly in time and frequency. We model a mock visibility of an EoR signal as a random Gaussian signal. We add the two together to form $\textbf {x} = \textbf {x}_{\rm FG} + \textbf {x}_{\rm EoR}$. Real parts are shown here.\relax }}{29}{figure.caption.14}
\contentsline {figure}{\numberline {2.2}{\ignorespaces The estimated covariance matrices (top row) and inverse covariance-weighted data (bottom row) for FG only (left), EoR only (middle), and FG + EoR (right). Real parts are shown here.\relax }}{30}{figure.caption.15}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Resulting power spectrum estimates for the toy model simulation described in Chapter \ref {sec:toymodel} --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). The power spectrum of the foregrounds peaks at a $k$-mode based on the frequency of the sinusoid used to create the mock FG signal. In the two panels, we compare using empirically estimated inverse covariance weighting where $\textbf {C}$ is derived from the data (left), and projecting out the zeroth eigenmode only (right). In the former case, signal loss arises from the coupling of the eigenmodes of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ to the data. There is negligible signal loss when all eigenmodes besides the foreground one are no longer correlated with the data. \relax }}{31}{figure.caption.16}
\contentsline {figure}{\numberline {2.4}{\ignorespaces The convergence level, as defined by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:converge}\unskip \@@italiccorr )}}, of empirically estimated covariances of mock EoR signals with different numbers of independent samples. In red, the mock EoR signal is comprised entirely of independent samples (100 of them). Subsequent colors show time-averaged signals. As the number of realizations increases, we see that the empirical covariances approach the true covariances. With more independent samples, the quicker an empirical covariance converges (i.e., the quicker it decouples from the data), and the less signal loss we would expect to result.\relax }}{34}{figure.caption.17}
\contentsline {figure}{\numberline {2.5}{\ignorespaces The convergence level, as defined by Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:converge_eig}\unskip \@@italiccorr )}}, of empirically estimated eigenvectors for different numbers of mock data realizations. The colors span from the 0th eigenmode (has the highest eigenvalue) to the 19th eigenmode (has the lowest eigenvalue), where they are ordered by eigenvalue in descending order. This figure shows that the zeroth eigenmode converges the quickest, implying that eigenvectors with eigenvalues that are substantially different than the rest (the FG-dominated mode has a much higher eigenvalue than the EoR modes) are able to converge to the true eigenvectors the quickest. On the other hand, eigenmodes $1$-$19$ have similar eigenvalues and are slower to converge because of degeneracies between them.\relax }}{35}{figure.caption.18}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Our ``fringe-rate filtered" (time-averaged) toy model dataset. We average every four samples together, yielding $25$ independent samples in time. Real parts are shown here.\relax }}{35}{figure.caption.19}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Resulting power spectrum estimate for the ``fringe-rate filtered" (time-averaged) toy model simulation --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). We use empirically estimated inverse covariance weighting where $\textbf {C}$ is computed from the data. There is a larger amount of signal loss than for the non-averaged data, a consequence of weighting by eigenmodes that are more strongly coupled to the data due to there being fewer independent modes in the data.\relax }}{37}{figure.caption.20}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Resulting power spectra estimates for our ``fringe-rate filtered" (time-averaged) toy model simulation --- foregrounds only (blue), EoR only (red), and the weighted FG + EoR dataset (green). We show four alternate weighting options that each minimize signal loss, including modeling the covariance matrix of EoR (upper left), regularizing $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ by adding an identity matrix to it (upper right), using only the first three eigenmodes of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ (lower left), and keeping only the diagonal elements of $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \textbf {C}$}\mathaccent "0362{\textbf {C}}$ (lower right). The first case (upper left) is not feasible in practice since we do not know $\textbf {C}_{\rm FG}$ and $\textbf {C}_{\rm EoR}$ like we do in the toy model.\relax }}{38}{figure.caption.21}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Error estimation from bootstrapping as a function of the number of elements drawn per bootstrap when sampling with replacement. The star represents the standard deviation of $N_{\rm boot}=500$ bootstraps, each created by drawing $1000$ elements (with replacement) from a length $1000$ array of a Gaussian random signal. The black points correspond to time-averaged data (correlated data) which has $100$ independent samples. They illustrate how errors can be under-estimated if drawing more elements than there are independent samples in the data. The estimated errors match up with the theoretical prediction only at $N=100$.\relax }}{45}{figure.caption.22}
\contentsline {figure}{\numberline {2.10}{\ignorespaces A null jackknife test shown as the power spectrum difference between two measurements (black), compared to the power spectrum of noise alone (green). Because the null test is not consistent with noise, it suggests the presence of a systematic in either $\textbf {x}_{1}$ or $\textbf {x}_{2}$. Null tests of clean measurements should be consistent with thermal noise.\relax }}{50}{figure.caption.23}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Power spectrum estimates for $\textbf {x}_{1}$ and $\textbf {x}_{2}$, two jackknives of the toy model. They suggest the presence of a systematic in $\textbf {x}_{2}$ only, illustrating how jackknives can be used to tease out excesses. Clean measurements should remain consistent despite the jackknife taken.\relax }}{50}{figure.caption.24}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces The PAPER-64 antenna layout. We use only $10$ of the $30$ m East/West baselines for the analysis in this chapter (i.e., a subset of the shortest horizontal spacings).\relax }}{53}{figure.caption.25}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Top: the normalized optimal power-spectrum sensitivity weighting in fringe-rate space for our fiducial baseline and Stokes I polarization beam. Bottom: the time domain convolution kernel corresponding to the top panel. Real and imaginary components are illustrated in cyan and magenta, respectively, with the absolute amplitude in black. The fringe-rate filter acts as an integration in time, increasing sensitivity but reducing the number of independent samples in the dataset.\relax }}{56}{figure.caption.26}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The PAPER-128 antenna layout. There are 112 antennas arranged in a grid layout which are used for power spectrum analyses. The addition of 16 outrigger antennas is used to increase \textit {uv}-plane sampling for imaging analyses.\relax }}{59}{figure.caption.27}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Visibility amplitudes as a function of LST for different Julian days of data (colors). The left column shows the data before (top) and after (bottom) the flagging of outlier days for Epoch 1. The right column shows similar data for Epoch 2. After flagging, visibilities show good day-to-day agreement across an epoch.\relax }}{61}{figure.caption.29}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Waterfall plots of visibility amplitudes for a ``good" reference day (left) in Epoch 2 and ``bad" day (right). We exclude corrupted data for specific days found with our metric.\relax }}{62}{figure.caption.30}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Waterfall plots of visibility amplitudes for four different polarizations and two different baselines. Antenna 26 is found to be cross-polarized because its feed was rotated by 90 degrees, and hence its ``X" and ``Y" polarization states are mis-labeled. Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:psa128_crosspol}\unskip \@@italiccorr )}} captures visibility amplitudes like the ones shown here in order to automatically detect cross-polarized antennae.\relax }}{63}{figure.caption.31}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Flagged antennas, found using Equation \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:psa128_badant}\unskip \@@italiccorr )}}, are marked in black for each antenna number (x-axis) and Julian date (y-axis). The left column shows flags for XX polarization, and the right column shows flags for YY polarization. The top row shows flags for Epoch 1 and the bottom row shows flags for Epoch 2. We remove antennas that are flagged greater than 50\% of the time per epoch.\relax }}{64}{figure.caption.32}
\contentsline {figure}{\numberline {5.6}{\ignorespaces {\tt FirstCal} phase solutions for Antenna 1 (Epoch 1, XX polarization) where no antennas are flagged (top left) and some antennas are flagged (via the methods described in Chapter \ref {sec:psa128_badant}, top right). Omnical $\chi ^{2}$ results are also shown for the two cases (bottom). We do not include any of the 16 dead antennas associated with correlator FX2. It is crucial to flag misbehaving antennas (especially extreme outlier antennas) prior to redundant calibration, motivating the development of automated quality assessment tools prior to the post-processing of data.\relax }}{66}{figure.caption.33}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Power spectrum results for PAPER-128 season 1 data for two redshifts (rows) and two epochs (columns), using one baseline separation-type only (30\tmspace +\thinmuskip {.1667em}m East/West baselines). Black and gray points represent positive and negative power spectrum values, respectively, with $2\sigma $ error bars determined from bootstrapping. The $2\sigma $ theoretical noise sensitivity prediction is shown in green. Gray shaded regions correspond to theoretical errors on each data point.\relax }}{69}{figure.caption.34}
\addvspace {10\p@ }
\addvspace {10\p@ }
